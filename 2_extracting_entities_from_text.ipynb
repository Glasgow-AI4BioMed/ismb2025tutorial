{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7-5Y-5tdNc8"
      },
      "source": [
        "# Extracting entities from text\n",
        "\n",
        "This hands-on session will introduce the process to identify important biomedical concepts (e.g. drugs, diseases, etc) that are mentioned in text."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465bb706",
      "metadata": {},
      "source": [
        "**NOTE:** If you are running this with Colab, you should make a copy for yourself. If you don't, you may lose any edits you make. To make a copy, select `File` (top-left) then `Save a Copy in Drive`. If you are not using Colab, you may need to install some prerequisites. Please see the instructions in the [Github repository](https://github.com/Glasgow-AI4BioMed/ismb2025tutorial)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd83d594",
      "metadata": {},
      "source": [
        "## Getting data\n",
        "\n",
        "As in the previous sessions, we'll download some data that we'll use later in this tutorial with the commands below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9306873",
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O data.zip https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EZS4UymC9ENLk3BGcO_1CeMBRz6NE34JZNWjwpm7X9kC8w?download=1\n",
        "!unzip -qo data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDdorJ-P658g"
      },
      "source": [
        "## Applying named entity recognition\n",
        "\n",
        "The first step in biomedical information extraction is to figure out which words refer to various biomedical entities. Which words refer to diseases, genes, etc.? We can use a named entity recognition approach for this and the specific model we use will determine which types of entities we can identify.\n",
        "\n",
        "The HuggingFace library is the standard way to access transformer-based language models and apply them for standard tasks. We'll use a `token-classification` pipeline with the [Glasgow-AI4BioMed/bioner_medmentions_st21pv](https://huggingface.co/Glasgow-AI4BioMed/bioner_medmentions_st21pv) model. This is a model trained on MedMentions which is one of the well-known biomedical text datasets. It identifies biomedical concepts mentioned in text and categorizes them with a large set of categories including *Chemicals & Drugs* and *Devices*. Check out the [model page](https://huggingface.co/Glasgow-AI4BioMed/bioner_medmentions_st21pv) for the full list.\n",
        "\n",
        "To set that up, we use the code below that will fetch the model and prepare it for token classification. It may take a minute to get it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner_pipeline = pipeline(\"token-classification\", model=\"Glasgow-AI4BioMed/bioner_medmentions_st21pv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f141b3ba",
      "metadata": {},
      "source": [
        "We can apply the token classification system to some text by calling it with the input text as below. This will return information about the words that have been identified as different types of biomedical entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"A recent study shows that metformin suppresses AKT1 activation in hepatocellular carcinoma.\"\n",
        "ner_pipeline(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a9d0e72",
      "metadata": {},
      "source": [
        "Note that some of the words have been categorised into different groups. And that they have `B-` or `I-` as prefixes. These signify whether the word is the beginning of an entity mention (with `B-`) or a continuation where it is inside the entity mention (with `I-`). This is known as [Insideâ€“outsideâ€“beginning](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) tagging.\n",
        "\n",
        "Practically, we often don't care about the individual words but want to group things up. So that the words `\"small cell lung cancer\"` which might be tagged with `[\"B-DISEASE\", \"I-DISEASE\", \"I-DISEASE\", \"I-DISEASE\"]` is extracted as a single thing identified with label `DISEASE`. We can add an `aggregation_strategy` to the token-classification pipeline below which will do that for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8a0f0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "ner_pipeline = pipeline(\"token-classification\", \n",
        "                        model=\"Glasgow-AI4BioMed/bioner_medmentions_st21pv\",\n",
        "                        aggregation_strategy=\"max\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e0ac9e",
      "metadata": {},
      "source": [
        "And then when we apply it to text, we will get spans of text tagged with different labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c859483",
      "metadata": {},
      "outputs": [],
      "source": [
        "entities = ner_pipeline(text)\n",
        "entities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b67de1e1",
      "metadata": {},
      "source": [
        "For every entity, we get a `start` and `end` which provide coordinates into the input string. For instance, we can check that the text of the final entity matches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "759cc08f",
      "metadata": {},
      "outputs": [],
      "source": [
        "text[66:90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOxbwbTmtnH"
      },
      "source": [
        "## Pre-prepared sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03fdf08",
      "metadata": {},
      "source": [
        "We have pre-prepared some sentences that we'll work with. They contain lots of biomedical entities. Let's load it up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('data/entity_sentences.json') as f:\n",
        "  sentences = json.load(f)\n",
        "\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63cc7eb7",
      "metadata": {},
      "source": [
        "Let's take a quick look at the first few:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz5dnhPS7Gci"
      },
      "source": [
        "### ðŸ“‹ Task 1: Chemical and drug sentences\n",
        "\n",
        "Now it's time for the first task of this hands-on session. Your task is to find every sentence from the pre-prepared set that contains a chemical (called 'Chemicals & Drugs' by the NER model) and a disease (called a 'Disorders' by the model). You should find that there are 42 unique sentences that contain entities tagged as 'Chemicals & Drugs' and 'Disorders'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6687a81",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>ðŸ”‘ Click to see the answer ðŸ”‘</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "chemical_disease_sentences = []\n",
        "for text in tqdm(sentences):\n",
        "  \n",
        "  entities = ner_pipeline(text)\n",
        "\n",
        "  chemicals = [ entity['word'] for entity in entities if entity['entity_group'] == 'Chemicals & Drugs' ]\n",
        "  diseases = [ entity['word'] for entity in entities if entity['entity_group'] == 'Disorders']\n",
        "\n",
        "  if chemicals and diseases:\n",
        "    chemical_disease_sentences.append((text, chemicals, diseases))\n",
        "\n",
        "len(chemical_disease_sentences)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1c47a0",
      "metadata": {},
      "source": [
        "There are some entity types that are more fine-grained than X or Y. For instance, 'Neoplasm process' is a subtype of 'Disease or Syndrome'. The tree of entity categories can be viewed [on this page](https://www.nlm.nih.gov/research/umls/META3_current_semantic_types.html). You could go further and find all sentences that mention at least one disease (including its subtypes) or chemical (including its subtypes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXCJuTDdGkV"
      },
      "source": [
        "## Entity linking\n",
        "\n",
        "Figuring out which words are different entity types is generally only half the challenge. We want to know which specific biomedical entities are being discussed. This can be challenging for several reasons:\n",
        "\n",
        "- Entities can be known by many different names including some that aren't documented in common lists of drug/gene/etc names\n",
        "- Mentions may be ambiguous: does APC refer to \"Adenomatous Polyposis Coli\" or \"Activated Protein C\"?\n",
        "- Mentions may not map perfectly to existing entity name lists, perhaps due to misspellings. For example, \"NSCLCL\" is probably a mistype of the acronym for \"non-small cell lung cancer\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1975210c",
      "metadata": {},
      "source": [
        "## Using vector search\n",
        "\n",
        "Let's explore a technique that uses dense vectors to represent our different entities. We'll use the [Disease Ontology](https://disease-ontology.org/) for mapping our identified mentions of diseases. For ease, we have pre-prepared a JSON version of the ontology. The ontology can be [downloaded](https://disease-ontology.org/downloads/) in standard ontology formats such as OBO and OWL.\n",
        "\n",
        "Let's load up the pre-prepared JSON one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('data/disease_ontology.json') as f:\n",
        "  disease_ontology = json.load(f)\n",
        "\n",
        "len(disease_ontology)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa6ad6b",
      "metadata": {},
      "source": [
        "We can take a look at a random term from this file. We can see that there is an identifier, a standard name and a list of aliases that is known by. The full Disease Ontology (which we won't use in this session) also provides a lot of additional information including descriptions, links with other ontologies and connections to other ontology terms (e.g. its parent term)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disease_ontology[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f94e28a3",
      "metadata": {},
      "source": [
        "To create a dense vector for a term, we will use [SapBERT](https://github.com/cambridgeltl/sapbert). It is a transformer-based model that has been trained to generate similar vectors for terms that refer to the same entity. So \"non-small cell lung cancer\" and \"NSCLC\" should give similar vectors. We can then use that similarity to figure out the most likely terms in an ontology that some text refers to.\n",
        "\n",
        "Let's load up SapBERT and use a `feature-extraction` pipeline that enables us to get the vectors from some text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = \"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\"\n",
        "extractor = pipeline(\"feature-extraction\", model=model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d3679a",
      "metadata": {},
      "source": [
        "Let's apply it to some text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"cold\"\n",
        "\n",
        "features = extractor(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b2a237",
      "metadata": {},
      "source": [
        "If you print out the result, you get lots and lots of numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0496fb71",
      "metadata": {},
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b02ddd9",
      "metadata": {},
      "source": [
        "We need to pull out one specific output. Each token in the text is transformed into a vector that is 768 elements wide (which is a common trait of BERT models). We'll use the [numpy library](https://numpy.org/) to make it nicer to work with. If we convert the result with numpy, we can see that it is a matrix of 1x3x768. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8cda0d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "context_vectors = np.array(features)\n",
        "context_vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0f6938",
      "metadata": {},
      "source": [
        "The vector we want is the first one (with index 0) as that's how SapBERT works. So, we'll use the first row of the matrix (so the first 768-wide vector) to represent this entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mention_vector = context_vectors[0,0,:]\n",
        "\n",
        "mention_vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6688fa52",
      "metadata": {},
      "source": [
        "This vector is a numeric representation of \"cold\". We want to compare this vector with vectors that represent every term in the Disease Ontology. We have pre-processed the Disease Ontology dataset beforehand. Let's load it up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "disease_ontology_vectors = np.load(\"data/disease_ontology_vectors.npy\")\n",
        "disease_ontology_vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ffe6c8",
      "metadata": {},
      "source": [
        "This shows that we have a vector for 14398 elements. Let's check how many elements we have in our preprocessed Disease Ontology set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b45afc",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(disease_ontology)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f10ff3b",
      "metadata": {},
      "source": [
        "Great. We have one vector for every element in the ontology.\n",
        "\n",
        "Now if we wanted to get a score for an element with our SapBERT-created vectors, we can use the [cosine similarity metric](https://en.wikipedia.org/wiki/Cosine_similarity). For instance, let's look at element 100:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa4df87",
      "metadata": {},
      "outputs": [],
      "source": [
        "disease_ontology[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579b9f19",
      "metadata": {},
      "source": [
        "We can get the corresponding vector with `disease_ontology_vectors[100]`. To compare it to our `mention_vector`, we will use the [cosine_similarity function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) from scikit-learn. We have to use `.reshape` to turn the 1D vectors into 2D matrices which the function expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59e83e28",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity(mention_vector.reshape(1,-1), disease_ontology_vectors[100].reshape(1,-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8f0dd2",
      "metadata": {},
      "source": [
        "Is that a high or low similarity? Really it only matters in comparison to all the other possible entities in the Disease Ontology.\n",
        "\n",
        "Hence, we want to score everything in the Disease Ontology and see which ones give the highest values. We can do that by multiplying the vector for our term against the entire matrix of vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = cosine_similarity(mention_vector.reshape(1,-1), disease_ontology_vectors).flatten().tolist()\n",
        "len(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32809f83",
      "metadata": {},
      "source": [
        "Now we have scores for all the terms when trying to match \"common cold\". What one gives us the highest score? We can use [np.argmax](https://numpy.org/doc/2.2/reference/generated/numpy.argmax.html) which tells you the index of the element with the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_idx = np.argmax(scores)\n",
        "top_score = scores[top_idx]\n",
        "top_idx, top_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400d12dc",
      "metadata": {},
      "source": [
        "Element 6824 gives us the highest score. Let's see what that is!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disease_ontology[top_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv1kk5p-rAqb"
      },
      "source": [
        "Excellent. In this case, the closest term for \"cold\" is likely the correct term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y68j7fPLrIIT"
      },
      "source": [
        "### ðŸ“‹ Task 2: SapBERT function\n",
        "\n",
        "Your task is to package up the approach for creating vectors for a disease name and finding the best match. Write a function (called `get_closest_disease`) that takes in text, runs SapBERT and returns the ID of the best disease ontology term.\n",
        "\n",
        "Try running the input \"nsclc\". You should find that the ontology term for \"lung non-small cell carcinoma\" is the closest match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85fd17d9",
      "metadata": {},
      "source": [
        "\n",
        "<details>\n",
        "<summary>ðŸ”‘ Click to see the answer ðŸ”‘</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "def get_closest_disease(disease_name):\n",
        "  features = extractor(disease_name)\n",
        "\n",
        "  context_vectors = np.array(features)\n",
        "\n",
        "  mention_vector = context_vectors[0,0,:]\n",
        "  \n",
        "  scores = cosine_similarity(mention_vector.reshape(1,-1), disease_ontology_vectors).flatten().tolist()\n",
        "\n",
        "  top_idx = np.argmax(scores)\n",
        "\n",
        "  return top_idx\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d6e4e64",
      "metadata": {},
      "source": [
        "Here's the example usage from the task instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d7a3d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_idx = get_closest_disease('nsclc')\n",
        "print(disease_ontology[top_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwGhJTRfNI1V"
      },
      "source": [
        "## Dictionary lookup\n",
        "\n",
        "Let's look at a simpler approach as well. Sometimes we have a fairly exhaustive list of possible names for entities. Chemical names can often be highly specific so let's look at using the list of aliases and matching them exactly.\n",
        "\n",
        "We'll use this when matching chemicals to the [ChEBI](https://www.ebi.ac.uk/chebi/) ontology. We have again preprocessed it for ease for this hands-on session. Let's load it below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('data/chebi.json') as f:\n",
        "  chebi = json.load(f)\n",
        "\n",
        "len(chebi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c43902ba",
      "metadata": {},
      "source": [
        "It is notably larger than the Disease Ontology. Let's see what an element of this ontology looks like. We have structured it in the same form as the previously loaded Disease Ontology: identifier, names and a list of aliases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chebi[178670]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d985da",
      "metadata": {},
      "source": [
        "Now we can make a lookup table that gives the index of term from the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chebi_lookup = {}\n",
        "for i,x in enumerate(chebi):\n",
        "  for alias in x['aliases']:\n",
        "    chebi_lookup[alias.lower()] = i\n",
        "  chebi_lookup[x['name'].lower()] = i\n",
        "\n",
        "len(chebi_lookup)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9a4860",
      "metadata": {},
      "source": [
        "For instance, if we looked up \"warfarin\", we would get index 115409:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c681679c",
      "metadata": {},
      "outputs": [],
      "source": [
        "chebi_lookup.get(\"warfarin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab694b8e",
      "metadata": {},
      "source": [
        "Let's check that that record is what we expect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09dd4d80",
      "metadata": {},
      "outputs": [],
      "source": [
        "chebi[115409]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37cad0d5",
      "metadata": {},
      "source": [
        "But if we search for something that didn't exist, we would get None:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd42b89f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(chebi_lookup.get(\"a fictional drug\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98418ae8",
      "metadata": {},
      "source": [
        "Notably, this approach ignores terms which may refer to multiple things. You could keep track of aliases that have multiple mappings, but for simplicity we won't here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fdq9S37Hnc"
      },
      "source": [
        "### ðŸ“‹ Task 3: Apply entity linkers\n",
        "\n",
        "The final task for this session is to apply the two different entity linking approaches to sentences that contain chemicals and diseases to see which appear the most. We've made a small dataset that can be loaded from `data/entity_linking_sentences.json` as below.\n",
        "\n",
        "For the disease, use the SapBERT approach and pick the highest scoring disease from the Disease Ontology. For the chemical, use the lookup approach (remembering to use lower-case strings when searching).\n",
        "\n",
        "For chemicals, you should find that the *sulfuric acid* appears 20 times. For diseases, you should find that *hypertension* appears 10 times.\n",
        "\n",
        "*Hint: You could use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) to help with counting frequent chemicals and diseases*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('data/entity_linking_sentences.json') as f:\n",
        "  entity_linking_sentences = json.load(f)\n",
        "\n",
        "entity_linking_sentences[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e418266f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82143e24",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>ðŸ”‘ Click to see the answer ðŸ”‘</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "with open('data/entity_linking_sentences.json') as f:\n",
        "  entity_linking_sentences = json.load(f)\n",
        "\n",
        "chemical_counts = Counter()\n",
        "disease_counts = Counter()\n",
        "\n",
        "for sentence in tqdm(entity_linking_sentences):\n",
        "  for chemical_mention in sentence['chemicals']:\n",
        "    chemical_idx = chebi_lookup.get(chemical_mention.lower())\n",
        "    \n",
        "    if chemical_idx:\n",
        "      chemical = chebi[chemical_idx]['name']\n",
        "      chemical_counts[chemical] += 1\n",
        "\n",
        "  for disease_mention in sentence['diseases']:\n",
        "    disease_idx = get_closest_disease(disease_mention)\n",
        "    disease = disease_ontology[disease_idx]['name']\n",
        "    \n",
        "    disease_counts[disease] += 1\n",
        "\n",
        "print(chemical_counts.most_common(3))\n",
        "print(disease_counts.most_common(3))\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc6c4c4",
      "metadata": {},
      "source": [
        "#### ðŸ’¡ Bonus Idea\n",
        "\n",
        "The two methods used here only use the mention text (i.e. the words describing the chemical/disease) and do not actually use the text of the whole sentence. Methods that use the full text may perform better, but are very computationally expensive. A combination of approaches may be best!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d019e562",
      "metadata": {},
      "source": [
        "## ðŸ End of Hands-on Session\n",
        "\n",
        "And that brings us to the end of the session. You've learned about:\n",
        "\n",
        "- Named entity recognition to figure out which words refer to entities of different types\n",
        "- Entity linking for deciding which entity from an ontology is being discussed\n",
        "  - Vector-based approaches such as SapBERT\n",
        "  - Dictionary matching using the known names and aliases of terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-OhQsbl3L9C"
      },
      "source": [
        "## ðŸ§° Optional Extras\n",
        "\n",
        "If you've got extra time, you could try some of the following ideas:\n",
        "\n",
        "- Some names in CHEBI may map to multiple items (e.g. \"erythromycin\" -> ('CHEBI:42355', 'erythromycin A') and ('CHEBI:48923', 'erythromycin')). Change the code to map those cases to \"AMBIGUOUS\". How might you deal with those cases better?\n",
        "- Use the code from the first hands-on session to get sentences from a PubMed document. Apply the NER model, and then the entity linking models. Count the number of chemicals and diseases that appear in that document."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
