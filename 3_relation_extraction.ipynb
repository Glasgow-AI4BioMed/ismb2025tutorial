{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDKMXrmUZJF1"
      },
      "source": [
        "# Relation extraction with co-occurrences and HuggingFace\n",
        "\n",
        "In this hands-on session, we'll explore identifying associations between entities in text. We'll first figure out how to find sentences that contain entities of interest, and then explore counting co-occurrences and later more complex relation extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce1555f",
      "metadata": {},
      "source": [
        "**NOTE:** If you are running this with Colab, you should make a copy for yourself. If you don't, you may lose any edits you make. To make a copy, select `File` (top-left) then `Save a Copy in Drive`. If you are not using Colab, you may need to install some prerequisites. Please see the instructions on the [Github Repo](https://github.com/Glasgow-AI4BioMed/ismb2025tutorial)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580abbaf",
      "metadata": {},
      "source": [
        "## Getting Data\n",
        "\n",
        "As in the previous sessions, we'll download some data that we'll use later on this tutorial with the commands below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bea0b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O data.zip https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/Ec8sygSj-zlAj6RXZHYGXqYBygZYM978Ts2FrTgBTfqmOQ?download=1\n",
        "!unzip -qo data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3EVc5Tk5Sn2"
      },
      "source": [
        "## Getting documents with pre-extracted entities\n",
        "\n",
        "In the last hands-on session, we looked at applying named entity recognition methods to identify mentions of biomedical concepts (e.g. diseases, etc). [PubTator](https://www.ncbi.nlm.nih.gov/research/pubtator3/) is an existing resource which contains entity annotations (for certain types) for PubMed abstracts and PubMed Central full-text articles. Instead of running NER tools in this session, let's look at getting annotated texts from PubTator.\n",
        "\n",
        "Similar to PubMed, you can get documents through [bulk download](https://ftp.ncbi.nlm.nih.gov/pub/lu/PubTator3) or through [their API](https://www.ncbi.nlm.nih.gov/research/pubtator3/api). Let's examine how to use their API to get a document. Below is the code to get the text and entity annotations for a single Pubmed abstract (pmid=20573926)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Example PubMed ID\n",
        "pmid = \"20573926\"\n",
        "\n",
        "# PubTator API endpoint for BioC XML\n",
        "url = f\"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocxml?pmids={pmid}\"\n",
        "\n",
        "# Make the request\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check for successful response\n",
        "assert response.status_code == 200\n",
        "\n",
        "document_xml = response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe4e8c5",
      "metadata": {},
      "source": [
        "This gets the document in an XML format known as BioC XML. Let's take a quick look at what that looks like. We'll use some code to pretty print the XML which puts in nice indenting for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xml.dom.minidom import parseString\n",
        "\n",
        "dom = parseString(document_xml)\n",
        "print(dom.toprettyxml(indent=\"  \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8ca7cc",
      "metadata": {},
      "source": [
        "The XML contains documents (with the &lt;document&gt; tag). Each document could contain multiple passages (e.g. the title, the abstract and sections of the paper could be treated as separate passages). Each passage contains text, along with information about the entities annotated there (the &lt;annotation&gt; tag).\n",
        "\n",
        "You can view the same document with all the annotations through the PubTator website: https://www.ncbi.nlm.nih.gov/research/pubtator3/publication/20573926\n",
        "\n",
        "Let's get back to the XML and save it out to a file for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d892f68e",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('example.bioc.xml','w') as f:\n",
        "  f.write(document_xml)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83008b9c",
      "metadata": {},
      "source": [
        "And we'll demonstrate loading a BioC XML file using the [bioc](github.com/bionlplab/bioc) Python package. We have to install it first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610eb40f",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install bioc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9236ccad",
      "metadata": {},
      "source": [
        "Then to load up that BioC XML file that we just saved, we can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bioc import biocxml\n",
        "\n",
        "with open('example.bioc.xml') as f:\n",
        "  collection = biocxml.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "303517d1",
      "metadata": {},
      "source": [
        "Let's see how many documents are in this file. We're expecting only one as we downloaded a single one earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(collection.documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e42cfb94",
      "metadata": {},
      "source": [
        "Excellent. Only one document. \n",
        "\n",
        "Let's see how many passages are in this single document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document = collection.documents[0]\n",
        "len(document.passages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aedcbd62",
      "metadata": {},
      "source": [
        "And let's output what the text is for each passage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for passage in document.passages:\n",
        "  print(passage.text)\n",
        "  print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af23452c",
      "metadata": {},
      "source": [
        "Great. It appears to be the title and the abstract as separate passages.\n",
        "\n",
        "We'll focus on the first passage for now as we explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06c1c6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "passage = document.passages[0]\n",
        "passage.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1515279c",
      "metadata": {},
      "source": [
        "\n",
        "Now let's see what metadata we can get for this document. With PubTator, we can check the metadata for each passage with `.infons`. It's a dictionary containing various fields including journal, year, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "passage.infons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc9034ef",
      "metadata": {},
      "source": [
        "And how about the annotations? These are the entities that have already been identified by PubTator. These include genes, diseases, chemicals, genetic variants and species.\n",
        "\n",
        "First, how many are there in this short passage?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(passage.annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9de5da",
      "metadata": {},
      "source": [
        "Let's iterate through them and provide some details:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for anno in passage.annotations:\n",
        "  print(f\"{anno.text=}\\n{anno.infons=}\\n{anno.total_span.offset=}\\n{anno.total_span.length=}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "880ce452",
      "metadata": {},
      "source": [
        "We get similar information to the previous hands-on session with named entity recognition methods. These annotations provide the location of the entities in the text (with the `.total_span.offset` and `.total_span.length` fields). They also provide the entity type with `.infons['Gene']`. And they have done entity linking to various ontologies and resources. The identifier is accessible through `.infons['identifier']`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkMWvZKS7tBs"
      },
      "source": [
        "## Calculating co-occurrences\n",
        "\n",
        "We'll start with the most straightforward way to identify relationships between entities - that they appear in lots of documents together. Co-occurrences may not provide nuance (by telling you the specific relation) but they can still be useful to identify that two concepts (e.g. two genes) appear to be connected because they appear together a lot. The co-occurrences could be in in sentences, paragraphs, paper abstracts or even whole papers. The granularity may depend on what you want to get, and how rare the terms are.\n",
        "\n",
        "Let's load up a set of documents that have already been annotated through the PubTator platform. We'll use them to calculate some co-occurrence counts. You can load the data with the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bioc import biocxml\n",
        "\n",
        "with open('data/cooccurrences.bioc.xml', \"r\") as f:\n",
        "    collection = biocxml.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f179ff0",
      "metadata": {},
      "source": [
        "The data is in BioC XML data format as we explored above. Let's see how many documents we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(collection.documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7469f20",
      "metadata": {},
      "source": [
        "That's a lot of documents! You need thousands (or possibly even millions) to get a good signal for identifying co-occurrences, especially for rarer terms.\n",
        "\n",
        "This dataset comes with text and also the annotations from PubTator. Let's remind ourselves what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2475df14",
      "metadata": {},
      "outputs": [],
      "source": [
        "collection.documents[0].passages[0].annotations[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f670e2f",
      "metadata": {},
      "source": [
        "They come with various fields including the text from the research paper, the database identifier that PubTator has linked them to and the entity type. In this case, `cyanogen bromide` has been linked to the MeSH database with ID: `MESH:D003488` and is a `Chemical`. You can use the MeSH Browser to view the page for [MESH:D003488](https://meshb.nlm.nih.gov/record/ui?ui=D003488).\n",
        "\n",
        "For co-occurrences, it's generally a good idea to use the normalized component (i.e. the ontology/database identifier) instead of the text form (which is 'cyanogen bromide' in this case) as the text form may vary from paper to paper. To make it easier to work with, let's make a lookup to go from the identifier to a text form.\n",
        "\n",
        "The code below creates a dictionary lookup from the type and identifier to the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_lookup = {}\n",
        "for i,doc in enumerate(collection.documents):\n",
        "  for passage in doc.passages:\n",
        "\n",
        "    for anno in passage.annotations:\n",
        "      quick_lookup[(anno.infons['type'],anno.infons['identifier'])] = anno.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b441bc25",
      "metadata": {},
      "source": [
        "That means we can lookup the text for the Chemical with identifier `MESH:D003488` with the code below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec466a9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_lookup[('Chemical','MESH:D003488')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7e9697",
      "metadata": {},
      "source": [
        "For a full project, it would be better to use the canonical name (i.e. the name that the entity is known by in the database) which would likely involve downloading the database (i.e. getting MeSH) or using an API to lookup the canonical name of entities.\n",
        "\n",
        "Now let's look at getting some co-occurrences. What entities are in identified in the first document in the collection? The code below outputs it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b424e9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = collection.documents[0]\n",
        "\n",
        "for passage in doc.passages:\n",
        "  for anno in passage.annotations:\n",
        "    print(anno.infons['type'], anno.infons['identifier'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff0f98c",
      "metadata": {},
      "source": [
        "While there are eight annotations, they relate to only two unique entities (a Chemical with identifier `MESH:D003488` and a Gene with identifier `213`). Let's see what those are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20da5937",
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_lookup[('Chemical','MESH:D003488')], quick_lookup[('Gene','213')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f4f3ab",
      "metadata": {},
      "source": [
        "It's the `cyanogen bromide` Chemical that we had before and the `albumin` gene. In this case, we would count this as a single co-occurrence of these two entities, as they have appeared in one document. Alternatively, we could also check whether they appear in the same sentence, but we will stick to the document level at the moment.\n",
        "\n",
        "Let's look at getting co-occurrence counts at scale:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fce60157",
      "metadata": {},
      "source": [
        "### Task 1\n",
        "\n",
        "Now it's time to go through thousands of documents in this collection (with `collection.documents`) and count up the number of documents that entities appear in, and the number of co-occurrences. You should get the identifiers for all the entities mentioned in each document, remove any duplicates (using a Python `set`) and then get every pair of entities. You could use the [itertools.combinations](https://docs.python.org/3/library/itertools.html#itertools.combinations) function to get the pairs.\n",
        "\n",
        "You should see that `MESH:D009369` and `9606` are the most commonly co-occurring pair. With `quick_lookup` you could check and see that they map to tumors and patients (or really mentions of humans)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5cf8b88",
      "metadata": {},
      "source": [
        "\n",
        "<details>\n",
        "<summary>🔑 Click to see the answer 🔑</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "cooccurrences = Counter()\n",
        "\n",
        "for doc in collection.documents:\n",
        "  identifiers = [ (anno.infons['type'],anno.infons['identifier']) for passage in doc.passages for anno in passage.annotations ]\n",
        "\n",
        "  unique_identifiers = sorted(set(identifiers))\n",
        "\n",
        "  for id1,id2 in itertools.combinations(unique_identifiers, 2):\n",
        "    cooccurrences[(id1,id2)] += 1\n",
        "\n",
        "cooccurrences.most_common(5)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic10UhVC7-lz"
      },
      "source": [
        "## A rule-based approach\n",
        "\n",
        "Let's move onto figuring out the relationships between entities. It can be important to know more than if two entities appear in the same context. Is that Chemical causing or treating that Disease?\n",
        "\n",
        "Sometimes, the text may follow specific patterns (e.g. on drug labels) or we want to extract relations that are worded in highly specific ways. Let's look at using patterns for this.\n",
        "\n",
        "We'll start by looking at an example sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = {'text': 'Metformin is used for type 2 diabetes, and studies have evaluated its efficacy in polycystic ovary syndrome.',\n",
        " 'chemicals': ['Metformin'],\n",
        " 'diseases': ['type 2 diabetes', 'polycystic ovary syndrome']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3344b524",
      "metadata": {},
      "source": [
        "The sentence follows a common pattern of `[CHEMICAL] is used for [DISEASE]`. Could we programmatically try to match that pattern for this sentence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rule = \"[CHEMICAL] is used for [DISEASE]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32126930",
      "metadata": {},
      "source": [
        "Let's get all possible pairs of chemical and disease in this sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs = [ (chemical,disease) for chemical in sentence['chemicals'] for disease in sentence['diseases'] ]\n",
        "pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec715ee1",
      "metadata": {},
      "source": [
        "There are two possible pairs of chemical/disease in this sentence. Let's see if any match our rule. We'll focus on the first one (which we do know will match):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chemical, disease = pairs[0]\n",
        "chemical, disease"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f105dfb",
      "metadata": {},
      "source": [
        "Let's take the sentence and replace the chemical and disease with those placeholders (`[CHEMICAL]` and `[DISEASE]`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_with_placeholders = sentence['text'].replace(chemical,'[CHEMICAL]').replace(disease,'[DISEASE]')\n",
        "sentence_with_placeholders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcdcf118",
      "metadata": {},
      "source": [
        "And then check if there is a match:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rule_matches = rule in sentence_with_placeholders\n",
        "\n",
        "print(f\"Match: {rule_matches}\")\n",
        "print(f\"  [CHEMICAL]={chemical}\")\n",
        "print(f\"  [DISEASE]={disease}\")\n",
        "print(f\"  {sentence_with_placeholders}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc71a363",
      "metadata": {},
      "source": [
        "Fantastic. It did match. Well what about the other pair?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "756acf23",
      "metadata": {},
      "outputs": [],
      "source": [
        "chemical, disease = pairs[1]\n",
        "print(chemical, disease)\n",
        "\n",
        "sentence_with_placeholders = sentence['text'].replace(chemical,'[CHEMICAL]').replace(disease,'[DISEASE]')\n",
        "print(sentence_with_placeholders)\n",
        "\n",
        "rule_matches = rule in sentence_with_placeholders\n",
        "print(f\"Match: {rule_matches}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd85ac41",
      "metadata": {},
      "source": [
        "No match as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfXa-uv8makQ"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "The task is to come up with more rules and apply them a dataset of sentences to extract more ways of saying that a chemical treats a disease. The dataset to load is `data/rulebased_sentences.json` and contains more sentences in a similar format to above. When coming up with rules, you could look at sentences that don't match any rules you've already come up with.\n",
        "\n",
        "Aim to come up with rules that match with over 20 sentences!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e0d6c9c",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>🔑 Click to see the answer 🔑</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "with open('data/rulebased_sentences.json') as f:\n",
        "  sentences = json.load(f)\n",
        "\n",
        "rules = [\n",
        "  \"[CHEMICAL] is used to treat [DISEASE]\",\n",
        "  \"[CHEMICAL] treats [DISEASE]\",\n",
        "  \"[CHEMICAL] is effective against [DISEASE]\",\n",
        "  \"[CHEMICAL] has been shown to treat [DISEASE]\",\n",
        "  \"[CHEMICAL] therapy for [DISEASE]\",\n",
        "  \"[CHEMICAL] has therapeutic effects on [DISEASE]\",\n",
        "  \"[CHEMICAL] is indicated for the treatment of [DISEASE]\",\n",
        "  \"[CHEMICAL] is administered to manage [DISEASE]\",\n",
        "  \"[CHEMICAL] is prescribed for [DISEASE]\",\n",
        "  \"[CHEMICAL] is a treatment option for [DISEASE]\",\n",
        "  \"[CHEMICAL] can be used for [DISEASE] therapy\",\n",
        "  \"[CHEMICAL] is beneficial for patients with [DISEASE]\",\n",
        "  \"Treatment of [DISEASE] with [CHEMICAL]\",\n",
        "  \"Use of [CHEMICAL] in the treatment of [DISEASE]\",\n",
        "  \"[CHEMICAL] alleviates symptoms of [DISEASE]\"\n",
        "]\n",
        "\n",
        "counts = Counter()\n",
        "\n",
        "for sentence in sentences:\n",
        "  pairs = [ (chemical,disease) for chemical in sentence['chemicals'] for disease in sentence['diseases'] ]\n",
        "\n",
        "  for chemical,disease in pairs:\n",
        "    sentence_with_placeholders = sentence['text'].replace(chemical,'[CHEMICAL]').replace(disease,'[DISEASE]')\n",
        "\n",
        "    if any( rule in sentence_with_placeholders for rule in rules):\n",
        "      counts[(chemical,disease)] += 1\n",
        "\n",
        "len(counts)\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df86faa7",
      "metadata": {},
      "source": [
        "There are advantages and disadvantages with the rule-based approach:\n",
        "\n",
        "Advantages:\n",
        "\n",
        "- The big advantage is that you have full control over how the relations are extracted, which may be very important for your project if specific wording is really needed. \n",
        "- It is very very fast. \n",
        "\n",
        "Disadvantages:\n",
        "- Need to write out lots of rules\n",
        "- There will always be cases that don't match a rule because of a small difference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HhFUjKB73UH"
      },
      "source": [
        "## A basic Open Information Extraction method"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88913604",
      "metadata": {},
      "source": [
        "Sometimes you may not be sure what information you want to extract, and certainly couldn't come up with rules to extract things. Open information extraction methods attempt to extract information without pre-determined labels, schema, etc. One approach to this is to extract the main verb between two entity mentions. The main verb often describes the action going on and is often the main relation that we care about.\n",
        "\n",
        "Let's set up an example sentence. Here the main verb is `binds` between the two entities and would be a useful thing to identify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = {\n",
        "    \"text\": \"Cetuximab binds to the epidermal growth factor receptor, blocking cancer cell proliferation.\",\n",
        "    \"entities\": [\"Cetuximab\", \"epidermal growth factor receptor\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b72e5b",
      "metadata": {},
      "source": [
        "Let's figure out where the two entities of interests are in the text (i.e. their string coordinates):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pair = (\"Cetuximab\", \"epidermal growth factor receptor\")\n",
        "\n",
        "loc1 = sentence['text'].index(pair[0])\n",
        "loc2 = sentence['text'].index(pair[1])\n",
        "\n",
        "loc1, loc2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bedc0ea0",
      "metadata": {},
      "source": [
        "We can use spaCy to parse the text and gets the individual tokens with the parts-of-speech as was shown in the first hands-on session. Let's do that to this sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d851adf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(sentence['text'])\n",
        "\n",
        "for token in doc:\n",
        "  print(f\"{token.pos_}: '{token.text}' at {token.idx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4891f90",
      "metadata": {},
      "source": [
        "We want to identify the verb that occurs between our two entities (at positions 0 and 23). Let's adjust the spaCy code to get it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    if token.pos_ == \"VERB\" and token.idx > loc1 and token.idx < loc2:\n",
        "        print(f\"{pair} {token.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7389fd2",
      "metadata": {},
      "source": [
        "You could apply this at scale to find the main verbs between two entities occurring in the same sentence. This has some advantages and disadvantages too:\n",
        "\n",
        "Advantages:\n",
        "- You don't need to decide the relation types you want to extract up front\n",
        "- It can help explore possible information to extract\n",
        "- It can be fairly fast\n",
        "\n",
        "Disadvantages:\n",
        "- It won't catch negative cases (e.g. \"Cetuximab never binds to TERT\")\n",
        "- There is more to meaning than the main verb\n",
        "- The main verb may not be directly connecting the two entities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56353160",
      "metadata": {},
      "source": [
        "## A transformer model for relation classification\n",
        "\n",
        "A machine learning model can also be used to classify the relationship between two entities in some text. One challenge of this is that you need annotated data to build and evaluate your model.\n",
        "\n",
        "We will use a model that has been trained on labels generated by a larger language model. This has certain limitations as the labels will likely contain some errors. However, it demonstrates how a machine learning model can be applied. The model we will apply is [Glasgow-AI4BioMed/synthetic_relex](https://huggingface.co/Glasgow-AI4BioMed/synthetic_relex). First, let's load it up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e60b0f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"Glasgow-AI4BioMed/synthetic_relex\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da83c14",
      "metadata": {},
      "source": [
        "The input to the model is text with the two entities of interest wrapped with `[E1][/E1]` and `[E2][/E2]` tags. Those denote the first and second entity in a relation.\n",
        "\n",
        "The classifier then predicts the label of the relation when text is passed to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef934f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier(\"[E1]Paclitaxel[/E1] is a common chemotherapy used for [E2]lung cancer[/E2].\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986b58f0",
      "metadata": {},
      "source": [
        "This model can classify a lot of different relation types including *treats*, *upregulates*, *binds*, etc between two entities. Check the [model page](https://huggingface.co/Glasgow-AI4BioMed/synthetic_relex) to see the full list.\n",
        "\n",
        "The `[E1][/E1]` and `[E2][/E2]` tags tell you the subject and object of the relation as there is directionality in the relations. The relation E1→E2 is different from E2→E1. If we switch the tags around in the text above, we get a different result and a prediction of no relation for this case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91c453d",
      "metadata": {},
      "outputs": [],
      "source": [
        "output = classifier(\"[E2]Paclitaxel[/E2] is a common chemotherapy used for [E1]lung cancer[/E1].\")\n",
        "\n",
        "# Let's just get the label this time\n",
        "output[0]['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2179613a",
      "metadata": {},
      "source": [
        "Make up your own sentence and see what works for the classifier and what doesn't."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e6b534",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier(\"Your own text here (remember to include the [E1][/E1] and [E2][/E2] tags).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJANWC68An7"
      },
      "source": [
        "### Task 3\n",
        "\n",
        "Your task is to apply the [Glasgow-AI4BioMed/synthetic_relex](https://huggingface.co/Glasgow-AI4BioMed/synthetic_relex) relation classifier model to a dataset of sentences that contain two entities and count the number of labels. You'll need to insert the `[E1][/E1]` and `[E2][/E2]` tags into the sentence text. Then you run the model with the `classifier` and get out the label. You should find that there are 48 sentences that give the `inhibits` relation.\n",
        "\n",
        "Here's some code to load up the small dataset of sentences. Each sentence has exactly two entities which you should find the relationship between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('data/relex_sentences.json') as f:\n",
        "  sentences = json.load(f)\n",
        "\n",
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95de82a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb748008",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>🔑 Click to see the answer 🔑</summary>\n",
        "\n",
        "Here is the code for the task:\n",
        "\n",
        "```python\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "label_counts = Counter()\n",
        "\n",
        "for sentence in tqdm(sentences):\n",
        "  entity1, entity2 = sentence['entity1'], sentence['entity2']\n",
        "\n",
        "  sentence_with_tags = sentence['text'].replace(entity1,f'[E1]{entity1}[/E1]').replace(entity2,f'[E2]{entity2}[/E2]')\n",
        "\n",
        "  output = classifier(sentence_with_tags)\n",
        "  label = output[0]['label']\n",
        "\n",
        "  label_counts[label] += 1\n",
        "\n",
        "label_counts\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4075b8",
      "metadata": {},
      "source": [
        "## End of Hands-on Session\n",
        "\n",
        "And that brings us to the end of the session. You've learned about:\n",
        "\n",
        "- Getting documents and annotations from [PubTator Central](https://www.ncbi.nlm.nih.gov/research/pubtator3/) using [their API](https://www.ncbi.nlm.nih.gov/research/pubtator3/api).\n",
        "- Calculating co-occurrence counts between entities for a large set of documents\n",
        "- Using rules to extract specifically phrased relations\n",
        "- Extracting the main verb to do open information extraction where you aren't sure what you want to extract\n",
        "- Applying a [BERT-based transformer model](https://huggingface.co/Glasgow-AI4BioMed/synthetic_relex) to classify relations between two entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0HRdo7AdQHo"
      },
      "source": [
        "## Optional Extras\n",
        "\n",
        "If you've got extra time, you could try some of the following ideas:\n",
        "\n",
        "- Calculate p-values for each co-occurrence by creating a contingency matrix of document counts of when two entities appear (and appear together)\n",
        "- Apply one of the other relation extraction methods (e.g. rule-based or open information extraction) to the final dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0e9384",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
