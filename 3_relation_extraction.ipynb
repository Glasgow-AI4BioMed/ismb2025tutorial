{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDKMXrmUZJF1"
      },
      "source": [
        "# Relation extraction with co-occurrences and HuggingFace\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3EVc5Tk5Sn2"
      },
      "source": [
        "## Getting documents with pre-extracted entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Example PubMed ID\n",
        "pmid = \"20573926\"\n",
        "\n",
        "# PubTator API endpoint for BioC XML\n",
        "url = f\"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocxml?pmids={pmid}\"\n",
        "\n",
        "# Make the request\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check for successful response\n",
        "if response.status_code == 200:\n",
        "    biocxml = response.text\n",
        "\n",
        "    # Save to a local file (optional)\n",
        "    with open(f\"example.bioc.xml\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(biocxml)\n",
        "\n",
        "    print(f\"BioC XML for PMID {pmid} saved as {pmid}.bioc.xml\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xml.dom.minidom import parseString\n",
        "\n",
        "dom = parseString(response.text)\n",
        "print(dom.toprettyxml(indent=\"  \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bioc import biocxml\n",
        "\n",
        "with open('example.bioc.xml') as f:\n",
        "  collection = biocxml.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(collection.documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document = collection.documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "len(document.passages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "passage = document.passages[0]\n",
        "passage.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "passage.infons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(passage.annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for anno in passage.annotations:\n",
        "  print(f\"{anno.text=}\\n{anno.infons=}\\n{anno.total_span.offset=}\\n{anno.total_span.length=}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir(anno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkMWvZKS7tBs"
      },
      "source": [
        "## Calculating co-occurrences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bioc import biocxml\n",
        "\n",
        "with open('collection.bioc.xml', \"r\") as f:\n",
        "    collection = biocxml.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(collection.documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quick_lookup = {}\n",
        "for i,doc in enumerate(collection.documents):\n",
        "  for passage in doc.passages:\n",
        "\n",
        "    for anno in passage.annotations:\n",
        "      if 'identifier' in anno.infons:\n",
        "        quick_lookup[anno.infons['identifier']] = (anno.infons['type'], anno.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(quick_lookup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "cooccurrences = Counter()\n",
        "counts = Counter()\n",
        "\n",
        "for i,doc in enumerate(collection.documents):\n",
        "  identifiers = [ anno.infons['identifier'] for passage in doc.passages for anno in passage.annotations if anno.infons.get('identifier','-') != '-' ]\n",
        "\n",
        "  unique_identifiers = set(identifiers)\n",
        "\n",
        "  counts += Counter(unique_identifiers)\n",
        "\n",
        "  for id1,id2 in itertools.combinations(unique_identifiers, 2):\n",
        "    cooccurrences[(id1,id2)] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (id1,id2),count in cooccurrences.most_common(50):\n",
        "  print(id1, quick_lookup[id1], id2, quick_lookup[id2], count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_count = len(collection.documents)\n",
        "\n",
        "count_1_and_2 = cooccurrences[(id1, id2)]\n",
        "\n",
        "count_1_and_not_2 = counts[id1] - count_1_and_2\n",
        "\n",
        "count_2_and_not_1 = counts[id2] - count_1_and_2\n",
        "\n",
        "count_not_1_or_2 = doc_count - count_1_and_2 - count_1_and_not_2 - count_2_and_not_1\n",
        "\n",
        "# 2x2 table\n",
        "contingency_table = [[count_1_and_2, count_1_and_not_2],\n",
        "                     [count_2_and_not_1, count_not_1_or_2]]\n",
        "\n",
        "contingency_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_1_and_2 / (count_1_and_2+count_1_and_not_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts[id1] / doc_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table, correction=False)\n",
        "\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (id1,id2),count in cooccurrences.items():\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzFQAdvrwU8k"
      },
      "source": [
        "## Task\n",
        "\n",
        "Do that calculation at scale for a big dataset of BioC files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic10UhVC7-lz"
      },
      "source": [
        "## A rule-based approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('sentences2.json') as f:\n",
        "  sentences = json.load(f)\n",
        "\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = {'text': 'Warfarin is used for stroke prevention, and studies suggest it may help manage deep vein thrombosis.',\n",
        " 'chemicals': ['Warfarin'],\n",
        " 'diseases': ['stroke prevention', 'deep vein thrombosis']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rule = \"[CHEMICAL] is used for [DISEASE]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs = [ (chemical,disease) for chemical in sentence['chemicals'] for disease in sentence['diseases'] ]\n",
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chemical, disease = pairs[0]\n",
        "chemical, disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_with_placeholders = sentence['text'].replace(chemical,'[CHEMICAL]').replace(disease,'[DISEASE]')\n",
        "sentence_with_placeholders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rule_matches = rule in sentence_with_placeholders\n",
        "\n",
        "print(f\"Match: {rule_matches}\")\n",
        "print(f\"  [CHEMICAL]={chemical}\")\n",
        "print(f\"  [DISEASE]={disease}\")\n",
        "print(f\"  {sentence_with_placeholders}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfXa-uv8makQ"
      },
      "source": [
        "## Task\n",
        "\n",
        "Apply to all the sentences and come up with more rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rules = [\n",
        "  \"[CHEMICAL] is used to treat [DISEASE]\",\n",
        "  \"[CHEMICAL] treats [DISEASE]\",\n",
        "  \"[CHEMICAL] is effective against [DISEASE]\",\n",
        "  \"[CHEMICAL] has been shown to treat [DISEASE]\",\n",
        "  \"[CHEMICAL] therapy for [DISEASE]\",\n",
        "  \"[CHEMICAL] has therapeutic effects on [DISEASE]\",\n",
        "  \"[CHEMICAL] is indicated for the treatment of [DISEASE]\",\n",
        "  \"[CHEMICAL] is administered to manage [DISEASE]\",\n",
        "  \"[CHEMICAL] is prescribed for [DISEASE]\",\n",
        "  \"[CHEMICAL] is a treatment option for [DISEASE]\",\n",
        "  \"[CHEMICAL] can be used for [DISEASE] therapy\",\n",
        "  \"[CHEMICAL] is beneficial for patients with [DISEASE]\",\n",
        "  \"Treatment of [DISEASE] with [CHEMICAL]\",\n",
        "  \"Use of [CHEMICAL] in the treatment of [DISEASE]\",\n",
        "  \"[CHEMICAL] alleviates symptoms of [DISEASE]\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for sentence in sentences:\n",
        "  pairs = [ (chemical,disease) for chemical in sentence['chemicals'] for disease in sentence['diseases'] ]\n",
        "\n",
        "  for chemical,disease in pairs:\n",
        "    sentence_with_placeholders = sentence['text'].replace(chemical,'[CHEMICAL]').replace(disease,'[DISEASE]')\n",
        "\n",
        "    if any( rule in sentence_with_placeholders for rule in rules) :\n",
        "      print(f\"{chemical} | {disease} | {sentence_with_placeholders}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HhFUjKB73UH"
      },
      "source": [
        "## A basic Open Information Extraction method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = {\n",
        "    \"text\": \"Cetuximab binds to the epidermal growth factor receptor, blocking cancer cell proliferation.\",\n",
        "    \"entities\": [\"Cetuximab\", \"epidermal growth factor receptor\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pair = (\"Cetuximab\", \"epidermal growth factor receptor\")\n",
        "\n",
        "loc1 = sentence['text'].index(pair[0])\n",
        "loc2 = sentence['text'].index(pair[1])\n",
        "\n",
        "loc1, loc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = sentence['text']\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    if token.pos_ == \"VERB\":\n",
        "        print(f\"Verb: '{token.text}' at {token.idx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJANWC68An7"
      },
      "source": [
        "## Task\n",
        "\n",
        "Apply one of the methods above to the large set of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('sentences-openie.json') as f:\n",
        "  sentences = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for sentence in sentences:\n",
        "  entity1, entity2 = sentence['entities']\n",
        "\n",
        "  doc = nlp(sentence['text'])\n",
        "\n",
        "  verbs = [ (token.idx, token.text) for token in doc if token.pos_ == \"VERB\" ]\n",
        "\n",
        "  loc1 = sentence['text'].index(entity1)\n",
        "  loc2 = sentence['text'].index(entity2)\n",
        "\n",
        "  loc1,loc2 = (loc2,loc1) if loc2 < loc1 else (loc1,loc2)\n",
        "\n",
        "  verbs_between = [ verb for verb_loc,verb in verbs if verb_loc > loc1 and verb_loc < loc2 ]\n",
        "\n",
        "  if len(verbs_between) == 1:\n",
        "    print(f\"{verbs_between[0]} | {entity1} | {entity2} | {sentence['text']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0HRdo7AdQHo"
      },
      "source": [
        "## Optional Extras\n",
        "\n",
        "- Calculate p-values for each co-occurrence by creating a contigency matrix of document counts of when two entities appear (and appear together)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
