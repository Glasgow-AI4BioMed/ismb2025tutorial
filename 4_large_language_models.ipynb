{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9AKGWc6dU6l"
      },
      "source": [
        "# Large language models\n",
        "\n",
        "- Run a small LLM (i.e. whatever I use in TaD) for an IE task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SydBmlcS-IAb"
      },
      "source": [
        "## Running an LLM locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open('sentences.json') as f:\n",
        "  sentences = json.load(f)\n",
        "\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"tiiuae/Falcon3-1B-Instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_text = 'EGFR binds to the EGFR receptor.'\n",
        "\n",
        "query = f\"{sentence_text}\\n\\nDoes the prior text contain a drug? Answe only Yes Or No\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot\"},\n",
        "    {\"role\": \"user\", \"content\": query},\n",
        "]\n",
        "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "print(tokenizer.decode(tokenized_chat[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = generator(messages, max_new_tokens=1)\n",
        "generated_message = result[0]['generated_text'][-1]\n",
        "\n",
        "print(generated_message['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYF6Clho-uUz"
      },
      "source": [
        "## Using an LLM through an API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSsVOH3v6ig6"
      },
      "source": [
        "https://aistudio.google.com/apikey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GEMINI_API_KEY = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.generativeai import GenerativeModel\n",
        "\n",
        "model = GenerativeModel(\"gemma-3-27b-it\")\n",
        "\n",
        "prompt = \"What Disease Ontology (DOID) term does GBM match to?\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MXWKcYWhRP"
      },
      "source": [
        "## Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUBv-3aWZLFD"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
